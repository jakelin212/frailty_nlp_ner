{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import configparser\n",
        "config = configparser.ConfigParser() #init\n",
        "config.read('../configs.ini') # init config with values from configs.ini\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719996561443
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VARIABLES\n",
        "# experiment of interest (experiment name must match the section name in configs.ini)\n",
        "#experiment = 'loneliness'\n",
        "#experiment = 'incontinence_v5'\n",
        "#experiment = 'mobility_v5.C.original'\n",
        "#experiment = 'Falling_NER_v3_20231114'\n",
        "#experiment = 'Mobility_2404_20240619'\n",
        "#experiment = 'Loneliness_beta0_20231123'\n",
        "experiment = 'Incontinence_NER_v5_20231208'\n",
        "\n",
        "# CONSTANTS from config\n",
        "# to save data\n",
        "data_folder = config[experiment]['data_folder'] # must exist\n",
        "data_subfolder = config[experiment]['data_subfolder'] # must exist\n",
        "# path to save folder\n",
        "data_save_folder_path = os.path.join(data_folder, data_subfolder)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719996561601
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_parquet(os.path.join(data_save_folder_path, 'tmp_BIO_labeled_data.parquet'))\n",
        "print(len(dataset))\n",
        "dataset = dataset[dataset['words'].apply(len) <= 512]\n",
        "print(len(dataset))\n",
        "dataset.reset_index(drop=True, inplace=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2561\n2561\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719996563784
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique original_ids\n",
        "unique_ids = dataset['text_id'].unique()\n",
        "\n",
        "# Split the unique_ids into training, test, and validation using a fixed seed for reproducibility\n",
        "train_ids, temp_ids = train_test_split(unique_ids, test_size=0.2, random_state=42)\n",
        "test_ids, val_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
        "\n",
        "# Using these IDs, filter the original dataset to get the respective data splits\n",
        "train_data = dataset[dataset['text_id'].isin(train_ids)]\n",
        "test_data = dataset[dataset['text_id'].isin(test_ids)]\n",
        "val_data = dataset[dataset['text_id'].isin(val_ids)]"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1719996563930
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some statistics\n",
        "print(len(train_data))\n",
        "print(len(val_data))\n",
        "print(len(test_data))\n",
        "\n",
        "print(\"\\nAs percentages\")\n",
        "print((train_data.shape[0]/unique_ids.shape[0]) *100)\n",
        "print((test_data.shape[0]/unique_ids.shape[0]) * 100)\n",
        "print((val_data.shape[0]/unique_ids.shape[0])*100)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2048\n257\n256\n\nAs percentages\n79.96876220226474\n9.996095275283093\n10.035142522452167\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719996564115
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save each split to a separate file\n",
        "train_data.to_parquet(os.path.join(data_save_folder_path, 'train_data.parquet'), index=False)\n",
        "test_data.to_parquet(os.path.join(data_save_folder_path, 'test_data.parquet'), index=False)\n",
        "val_data.to_parquet(os.path.join(data_save_folder_path, 'val_data.parquet'), index=False)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719996564269
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you do not see the files in the folder structure then refresh the view.\n",
        " \n",
        "**Now move on to training your model(s)!**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}